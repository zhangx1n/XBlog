import{_ as t,c as a,o as n,V as l}from"./chunks/framework.41330901.js";const e="/assets/rag和agent的关系.excalidraw.172970c8.png",u=JSON.parse('{"title":"LLM Agent 解读","description":"llm agent 解读","frontmatter":{"title":"LLM Agent 解读","time":877,"description":"llm agent 解读","navbar":true,"sidebar":false,"footer":true,"date":"2024-01-15T00:00:00.000Z","category":"Article","author":"Yi Ming","next":false,"tags":["深度学习","Agent"],"blog":"post","aside":"left","prev":false},"headers":[],"relativePath":"blog/posts/2024/llm_agent.md"}'),o={name:"blog/posts/2024/llm_agent.md"},r=l('<h1 id="什么是llm-agent" tabindex="-1">什么是llm Agent <a class="header-anchor" href="#什么是llm-agent" aria-label="Permalink to &quot;什么是llm Agent&quot;">​</a></h1><h1 id="引言" tabindex="-1">引言 <a class="header-anchor" href="#引言" aria-label="Permalink to &quot;引言&quot;">​</a></h1><p><img src="'+e+'" alt=""> 代理(agent)的核心思想是使用语言模型来选择要<strong>执行</strong>的<strong>一系列操作</strong>。在链中，一系列操作是硬编码的（在代码中）。在代理中，语言模型用作<strong>推理引擎</strong>，以确定要执行哪些操作以及按何种顺序执行。</p><p>简单的理解就是, 让llm成为大脑, 然后通过agent技术,可以让llm判断和使用工具拓展他的功能, 以达到完成复杂任务的目的.</p><hr><h1 id="工作流程" tabindex="-1">工作流程 <a class="header-anchor" href="#工作流程" aria-label="Permalink to &quot;工作流程&quot;">​</a></h1><p>本质上就是通过多轮对话, 读取结果,解读结果, 多轮来完成确定调用意图的意思.</p><p>流程简单的说,有几步:</p><ol><li>用户输入问题</li><li>通过prompt 编写思考意图(需要llm本身能力支持), 让llm作为推理的大脑, 要求其从用户输入的自然语言中, 在工具库中选择好应该使用的工具</li><li>然后让llm按照预设好的格式从问题中提取出使用这个工具所需要的入参(也是通过prompt)</li><li>最后让exexution engine (常规算法编写的提取参数匹配和执行工具), 读取llm的参数和工具使用的选择结果, 执行结果, 并且返回给用户.</li></ol><p>exexution engine: 这个就是做字符串和调用具体功能的映射功能, 之前就卡着这儿, 不知道具体的可能性是如何做到的, 可以通过正则,或者frontmatter(看具体设计的格式).</p><p>让大语言模型通过json 的格式生成回答,这个就很棒, 总体的意思就是这样一个意思, 然后解析json比较简单, 所以不需要重新设计字符串格式.</p><p>(之前我们让llm按照我们的格式要求生成三维数据的json格式, 然后直接解析那就是三维数据了, 这其实就是 agent的思想!)</p><blockquote><p><a href="https://python.langchain.com/docs/modules/agents/" target="_blank" rel="noreferrer">Agents | 🦜️🔗 Langchain</a><a href="https://www.zhihu.com/question/604480991/answer/3080252928" target="_blank" rel="noreferrer">(99+ 封私信 / 80 条消息) LangChain的agent是如何把自己的函数丢给LLMs的，是prompt吗？ - 知乎 (zhihu.com)</a></p></blockquote><h1 id="思考" tabindex="-1">思考 <a class="header-anchor" href="#思考" aria-label="Permalink to &quot;思考&quot;">​</a></h1><p><strong>问题:</strong> 为什么llm能够理解我让他以特定格式的json生成回答这种任务, 训练的时候需要特地的喂它这类json数据吗,还是不需要?</p><p><strong>GPT回答:</strong> LLM可以理解并生成特定格式的JSON是因为其在训练过程中接收到的大量数据包含多样性的信息，并且使用了强大的机器学习算法来挖掘这些数据的模式。</p><p>这些数据可能包括各种任务，包括生成特定格式的JSON。因此，即使没有特意将“生成特定格式的JSON”作为训练任务，只要训练数据包含了足够丰富和多样的任务，LLM也能学习到这个技能。</p><p>遇到这类任务时，LLM会依据用户的输入，理解任务需求，并用其学习的模式生成相应格式的JSON语句，完成任务。</p><p>总的来说，LLM的强大主要反映在两点。首先，它的训练数据涵盖了广泛的内容，使其能够处理多样性的任务；其次，它的机器学习算法能有效利用这些数据学习了如何处理各类任务，包括生成特定格式的JSON。</p><h1 id="llm-agent应用" tabindex="-1">llm Agent应用 <a class="header-anchor" href="#llm-agent应用" aria-label="Permalink to &quot;llm Agent应用&quot;">​</a></h1><p>和RAG的关系: 这种形式的一个特点就是, 目前增强的还是侧重于自然语言的任务和工作. 和<code>llm agent</code>相比, <code>agent</code>的功能可以囊括这个, agent还可以处理非自然语言的, 类似api之类的工作. 所以看起来, agent其实可以覆盖部分RAG的概念范围.</p><p>所以以后非文本的任务时候就可以考虑agent, agent囊括其他工具的调用. <img src="'+e+'" alt=""></p>',22),s=[r];function i(p,g,c,m,h,d){return n(),a("div",null,s)}const f=t(o,[["render",i]]);export{u as __pageData,f as default};
